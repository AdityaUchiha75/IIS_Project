{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import opencv_jupyter_ui as jcv2\n",
    "from feat import Detector\n",
    "from IPython.display import Image\n",
    "from feat.utils import FEAT_EMOTION_COLUMNS\n",
    "import time as t\n",
    "from time import sleep\n",
    "from furhat_remote_api import FurhatRemoteAPI\n",
    "from numpy.random import randint\n",
    "\n",
    "import time\n",
    "import sys\n",
    "import trace\n",
    "from pathlib import Path\n",
    "import multiprocessing\n",
    "import threading\n",
    "import os\n",
    "from torch import nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class thread_with_trace(threading.Thread):\n",
    "  def __init__(self, *args, **keywords):\n",
    "    threading.Thread.__init__(self, *args, **keywords)\n",
    "    self.killed = False\n",
    " \n",
    "  def start(self):\n",
    "    self.__run_backup = self.run\n",
    "    self.run = self.__run      \n",
    "    threading.Thread.start(self)\n",
    " \n",
    "  def __run(self):\n",
    "    sys.settrace(self.globaltrace)\n",
    "    self.__run_backup()\n",
    "    self.run = self.__run_backup\n",
    " \n",
    "  def globaltrace(self, frame, event, arg):\n",
    "    if event == 'call':\n",
    "      return self.localtrace\n",
    "    else:\n",
    "      return None\n",
    " \n",
    "  def localtrace(self, frame, event, arg):\n",
    "    if self.killed:\n",
    "      if event == 'line':\n",
    "        raise SystemExit()\n",
    "    return self.localtrace\n",
    " \n",
    "  def kill(self):\n",
    "    self.killed = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Furhat setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FURHAT_IP = \"127.0.1.1\"\n",
    "\n",
    "furhat = FurhatRemoteAPI(FURHAT_IP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "furhat.set_led(red=100, green=50, blue=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detector setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = Detector(device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, features_in=2, features_out=3):\n",
    "        super().__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(features_in, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, features_out),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.net(input)\n",
    "    \n",
    "path=Path(os.getcwd()).parent\n",
    "DIR_PATH=str(path) + '\\\\'\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = torch.load(Path(DIR_PATH + 'models\\\\best_model_12.pt') ).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "expression = {\"anger\": 6, \"disgust\": 5 , \"fear\": 4, \"happiness\": 1, \"neutral\": 0, \"sadness\": 2, \"surprise\": 3}\n",
    "def return_emo(loc):\n",
    "    for key,_ in expression.items():\n",
    "        if expression[key] == loc:\n",
    "            return key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMO_LIST= []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capture_and_return_emos(t):\n",
    "    fl = False\n",
    "    start= time.time()\n",
    "    cap = cv2.VideoCapture(1)\n",
    "    print(\"Capture on\")\n",
    "    flag=True\n",
    "    while flag: #or not event.is_set()\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Error: Unable to capture the frame.\")\n",
    "            break\n",
    "\n",
    "        detected_faces = detector.detect_faces(frame)\n",
    "        detected_landmarks = detector.detect_landmarks(frame, detected_faces)\n",
    "        detected_aus = detector.detect_aus(frame, detected_landmarks)\n",
    "\n",
    "        for faces,au_units in zip(detected_faces,detected_aus): #access only one frame\n",
    "            for i in range(len(faces)): #access all faces detected in the frame\n",
    "                au_arr=model(torch.tensor(au_units[i]).to(device)).cpu()\n",
    "                max_loc=np.argmax(au_arr.softmax(dim=0).numpy())\n",
    "                emotion=return_emo(max_loc)\n",
    "                EMO_LIST.append(emotion)\n",
    "                x, y, w, h, p = faces[i]\n",
    "                # Drawing a rectangle around the detected face\n",
    "                cv2.rectangle(frame, (int(x), int(y)), (int(w), int(h)), (0,0 , 255), 2)\n",
    "\n",
    "                # Displaying the emotion label on top of the rectangle\n",
    "                cv2.putText(frame, emotion, (int(x), int(y) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "                stop = time.time()\n",
    "                # if event.is_set():\n",
    "                #     flag=False\n",
    "                #     break\n",
    "                if stop - start >= t:\n",
    "                    print(fl)\n",
    "                    fl = True\n",
    "                    flag=False\n",
    "                    break                                   \n",
    "                 #key == 27:\n",
    "\n",
    "    # jcv2.destroyAllWindows()\n",
    "    cap.release()\n",
    "    print(\"Capture off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# event = threading.Event()\n",
    "# stop_threads = False\n",
    "# t1 = thread_with_trace(target = capture_and_return_emos(event,)) #lambda : stop_threads,\n",
    "\n",
    "# t1.start()\n",
    "# time.sleep(5)\n",
    "# event.set()\n",
    "# t1.kill()\n",
    "# # start = time.time()\n",
    "# # stop = time.time()\n",
    "# t1.join()\n",
    "# # if stop - start >=7:\n",
    "#     # stop_threads = True\n",
    "# fl=False\n",
    "\n",
    "# process1 = multiprocessing.Process(target=capture_and_return_emos(lambda: fl,))\n",
    "# process1.start()\n",
    "# start= time.time()\n",
    "# time.sleep(7)\n",
    "# stop = time.time()\n",
    "# if stop - start >= 7:\n",
    "#     fl = True\n",
    "# else:\n",
    "#     fl= False\n",
    "    \n",
    "# process1.terminate()\n",
    "# process1.kill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capture on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Audit\\anaconda3\\envs\\iis\\Lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\Audit\\anaconda3\\envs\\iis\\Lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\Audit\\anaconda3\\envs\\iis\\Lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\Audit\\anaconda3\\envs\\iis\\Lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\Audit\\anaconda3\\envs\\iis\\Lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\Audit\\anaconda3\\envs\\iis\\Lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\Audit\\anaconda3\\envs\\iis\\Lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\Audit\\anaconda3\\envs\\iis\\Lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\Audit\\anaconda3\\envs\\iis\\Lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\Audit\\anaconda3\\envs\\iis\\Lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n",
      "c:\\Users\\Audit\\anaconda3\\envs\\iis\\Lib\\site-packages\\torchvision\\transforms\\functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "Capture off\n"
     ]
    }
   ],
   "source": [
    "process1 = multiprocessing.Process(target=capture_and_return_emos(6)) #, daemon=False\n",
    "process1.start()\n",
    "process1.terminate()\n",
    "\n",
    "# time.sleep(7)\n",
    "# stop = time.time()\n",
    "# if stop - start >= 6:\n",
    "#     fl = True\n",
    "# else:\n",
    "#     fl= False\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "anger 2\n",
      "happiness 9\n",
      "neutral 5\n",
      "happiness 9\n"
     ]
    }
   ],
   "source": [
    "#len(EMO_LIST)\n",
    "max=0\n",
    "for i in np.unique(EMO_LIST):\n",
    "    print(i, np.char.count(EMO_LIST, i).sum())\n",
    "    if np.char.count(EMO_LIST, i).sum() > max:\n",
    "        max = np.char.count(EMO_LIST, i).sum()\n",
    "        emo = i\n",
    "print(emo, max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'neutral',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'anger',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'happiness',\n",
       " 'anger',\n",
       " 'happiness']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EMO_LIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.02\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "\n",
    "for i in range(10000):\n",
    "    print('', end='')\n",
    "    ft=time.time()\n",
    "\n",
    "print('\\n', f'{(ft-st):.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task1():\n",
    "    print(\"Task 1 assigned to thread: {}\".format(threading.current_thread().name))\n",
    "    print(\"ID of process running task 1: {}\".format(os.getpid()))\n",
    " \n",
    "def task2():\n",
    "    print(\"Task 2 assigned to thread: {}\".format(threading.current_thread().name))\n",
    "    print(\"ID of process running task 2: {}\".format(os.getpid()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ID of process running main program: {}\".format(os.getpid()))\n",
    "\n",
    "print(\"Main thread name: {}\".format(threading.current_thread().name))\n",
    "\n",
    "t1 = threading.Thread(target=task1, name='t1')\n",
    "t2 = threading.Thread(target=task2, name='t2')\n",
    "\n",
    "t1.start()\n",
    "t2.start()\n",
    "\n",
    "t1.join()\n",
    "t2.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
